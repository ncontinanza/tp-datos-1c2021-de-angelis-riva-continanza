{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "En este notebook entrenaremos tres modelos de MultinomialNB, uno con el mismo preprocesamiento del dataset realizado en la primera parte del TP, el segundo con la función `preprocessing_significantes`, y el último con el `preprocessing_equilibrado`, para estudiar cómo se comporta este modelo ante esas tres distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB\n",
    "\n",
    "# Preprocessing\n",
    "import utils\n",
    "import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Búsqueda\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "\n",
    "# Plots\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Otros\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre, comencemos por obtener el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este modelo en particular, nos interesa entrenar modelos con distintos valores del hiperparámetro alpha, que haremos variar entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'alpha': np.linspace(0,1,1000) }\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(model, params, scoring='roc_auc', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos, los preprocesamos con la primer función que mostraremos en este notebook, y escalamos los valores obtenidos entre 0 y 1 antes de entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df.drop('tiene_alto_valor_adquisitivo',1), df['tiene_alto_valor_adquisitivo'], random_state=112, stratify=df['tiene_alto_valor_adquisitivo'])\n",
    "X_train_1, X_test_1 = preprocessing.preprocessing_base_parte_1(X_train_1, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # Por default, en [0,1]\n",
    "\n",
    "X_train_1 = pd.DataFrame(scaler.fit_transform(X_train_1))\n",
    "X_test_1 = pd.DataFrame(scaler.transform(X_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1979s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 770 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 898 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1178 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1408 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1490 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1572 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1744 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1834 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1924 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2018 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2112 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2210 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2308 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2410 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2512 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2618 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1999s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 2760 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2980 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3200 tasks      | elapsed:   31.0s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gscv.fit(X_train_1, y_train_1)\n",
    "score = roc_auc_score(y_test_1, gscv.predict_proba(X_test_1)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_base = gscv.best_estimator_\n",
    "bayes_base.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1,bayes_base.predict(X_test_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que, si bien la métrica AUC-ROC arrojó un buen resultado, el accuracy es bastante bajo, y las demás métricas nos dan una idea de que el modelo seleccionado no generaliza nada bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(bayes_base, X_test_1, y_test_1, cmap=plt.cm.Blues, display_labels=['0', '1'], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien, a priori, parece dar buenos resultados para los True Positive y False Negative, vemos que los True Negative son muy escasos y tiene una cantidad indeseablemente alta de False Positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(bayes_base, X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de la curva y su lento crecimiento en el eje vertical nos ayuda a reforzar la idea de que no obtuvimos un buen clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Significantes\n",
    "\n",
    "Repetimos el procedimiento anterior, esta vez trabajando los datos con la función de preprocessing significantes para con un 90% de varianza explicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'alpha': np.linspace(0,1,1000) }\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(model, params, scoring='roc_auc', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('tiene_alto_valor_adquisitivo')]\n",
    "Y = df['tiene_alto_valor_adquisitivo']\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, Y, random_state=112, stratify=Y)\n",
    "X_train_2, X_test_2 = preprocessing.preprocessing_significantes(X_train_2, X_test_2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # Por default, en [0,1]\n",
    "\n",
    "X_train_2 = pd.DataFrame(scaler.fit_transform(X_train_2))\n",
    "X_test_2 = pd.DataFrame(scaler.transform(X_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gscv.fit(X_train_2, y_train_2)\n",
    "score = roc_auc_score(y_test_2, gscv.predict_proba(X_test_2)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de continuar, notemos que el alpha obtenido en este caso es muy chico, en comparación con el seleccionado para el modelo anterior que era bastante cercano a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_significantes = gscv.best_estimator_\n",
    "bayes_significantes.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una mejora en la métrica AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_2,bayes_significantes.predict(X_test_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, a pesar de haber obtenido un resultado decente según AUC-ROC, vemos que la clasificación es muy mala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(bayes_significantes, X_test_2, y_test_2, cmap=plt.cm.Blues, display_labels=['0', '1'], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el comportamiento es incluso peor que el modelo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(bayes_significantes, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Equilibrado\n",
    "\n",
    "Finalizaremos este análisis intentando obtener un mejor resultado al equilibrar la cantidad de muestras con bajo poder adquisitivo a la de muestras con alto poder adquisitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'alpha': np.linspace(0,1,1000) }\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(model, params, scoring='roc_auc', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('tiene_alto_valor_adquisitivo')]\n",
    "Y = df['tiene_alto_valor_adquisitivo']\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X, Y, random_state=112, stratify=Y)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = preprocessing.preprocessing_equilibrado(X_train_3, X_test_3, y_train_3, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train = MinMaxScaler() # Por default, en [0,1]\n",
    "scaler_test = MinMaxScaler() # Por default, en [0,1]\n",
    "\n",
    "X_train_3 = pd.DataFrame(scaler_train.fit_transform(X_train_3))\n",
    "X_test_3 = pd.DataFrame(scaler_test.fit_transform(X_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gscv.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el alpha seleccionado está casi en el límite superior del rango elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_equilibrado = gscv.best_estimator_\n",
    "bayes_equilibrado.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_3,bayes_equilibrado.predict(X_test_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien sigue sin ser un clasificador excelente, vemos una mejora sustancial respecto de los anteriores, al menos en términos de la generalización. Sin embargo, el accuracy empeoró."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(bayes_equilibrado, X_test_3, y_test_3, cmap=plt.cm.Blues, display_labels=['0', '1'], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de haber mejorado en algunos aspectos, ahora tenemos un número demasiado alto en los False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(bayes_equilibrado, X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, vemos que los falsos positivos crecen muy rápido en comparación con los verdaderos positivos, haciendo que la clasificación sea tan pobre como vimos.\n",
    "\n",
    "A modo de conclusión general, no vemos que MultinomialNB sea un modelo interesante para los objetivos de este trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistiendo los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bayes_base, open(\"Modelos/MultinomialNB/bayes_base.pickle\", \"wb\"))\n",
    "pickle.dump(bayes_significantes, open(\"Modelos/MultinomialNB/bayes_significantes.pickle\", \"wb\"))\n",
    "pickle.dump(bayes_equilibrado, open(\"Modelos/MultinomialNB/bayes_equilibrado.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de HoldOut\n",
    "\n",
    "Usaremos para predecir el NaiveBayes obtenido para el preprocessing significantes de 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_significantes = pickle.load(open(\"Modelos/MultinomialNB/bayes_significantes.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout():\n",
    "    dfv = utils.get_data()\n",
    "    Xv = dfv[dfv.columns.drop('tiene_alto_valor_adquisitivo')]\n",
    "    Xv = pd.get_dummies(Xv, drop_first=True)\n",
    "    Xv, _, _, _ = train_test_split(Xv, dfv['tiene_alto_valor_adquisitivo'], random_state=112)\n",
    "\n",
    "    ids, X = utils.get_holdout_data()\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    notInHoldout=[]\n",
    "    for c in Xv.columns:\n",
    "        if c not in X.columns:\n",
    "            notInHoldout.append(c)\n",
    "    X[notInHoldout] = 0\n",
    "\n",
    "    Xv, X = preprocessing.preprocessing_significantes(Xv, X, variance=0.9)\n",
    "    return ids, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, X = holdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.escribir_holdout(bayes_significantes.predict(X), \"3 - MultinomialNB\", ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
