{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polyphonic-banner",
   "metadata": {},
   "source": [
    "# Regresión logística\n",
    "\n",
    "La idea de este notebook es realizar una predicción mediante regresión logística utilizando los preprocessings:\n",
    "* Standard preprocessing parte 1\n",
    "* Preprocessing significantes 90% de varianza explicada\n",
    "* Primeras variables seleccionadas por un árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Preprocessing\n",
    "from preprocessing import standard_preprocessing_base_parte_1, preprocessing_significantes, preprocessing_mejores_por_arbol\n",
    "import utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Búsqueda\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import plot_roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "\n",
    "# Plots\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Otros\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-standing",
   "metadata": {},
   "source": [
    "## Modelo 1 - Standard Preprocessing parte 1\n",
    "\n",
    "Será entrenado con las siguientes variables:\n",
    "\n",
    "* **Ganancia/Pérdida declara en la bolsa argentina**: `ganancia_perdida_declarada_bolsa_argentina`\n",
    "* **Edad**: `edad`\n",
    "* **Rol familiar registrado**: `rol_familiar_registrado`\n",
    "* **Años estudiados**: `anios_estudiados`\n",
    "\n",
    "A las que se les aplicará una función de Standarización para que la regresión logísitca y su regularización funcionen correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('tiene_alto_valor_adquisitivo')]\n",
    "Y = df['tiene_alto_valor_adquisitivo']\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, Y, random_state=112)\n",
    "\n",
    "X_train_1, X_test_1 = standard_preprocessing_base_parte_1(X_train_1, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "params = [{'penalty': ['l1']        , 'C': np.logspace(-3, 3, 13), 'solver': ['saga'] },\n",
    "          {'penalty': ['l2']        , 'C': np.logspace(-3, 3, 13), 'solver': ['lbfgs']},\n",
    "          {'penalty': ['elasticnet'], 'C': np.logspace(-3, 3, 13), 'solver': ['saga'] , 'l1_ratio': np.linspace(0.1, 0.9, 9)}]\n",
    "\n",
    "gscv1 = GridSearchCV(model, params, scoring='roc_auc', n_jobs=-1, verbose=4, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv1.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-mumbai",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Los parámetros que mejor score obtuvieron para AdaBoost fueron:\", gscv1.best_params_)\n",
    "print(\"Con un Score (RocAUC) de: \", round(gscv1.best_score_, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-metadata",
   "metadata": {},
   "source": [
    "Realicemos ahora el modelo por fuera del gridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = gscv1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1,lr1.predict(X_test_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-exclusion",
   "metadata": {},
   "source": [
    "Vemos que el modelo tiene un accuracy de 84%. Un recall común para los ceros, un poco pobre para los unos, esto se verá reflejado en la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(lr1, X_test_1, y_test_1, cmap=plt.cm.Blues, display_labels=['0', '1'], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-bahamas",
   "metadata": {},
   "source": [
    "Vemos aquí que hay muchos Falsos negativos, es decir que el modelo no está pudiendo predecir correctamente a los unos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(lr1, X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_1, lr1.predict_proba(X_test_1)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-hopkins",
   "metadata": {},
   "source": [
    "Vemos que el RocAUC fue de 0.88, por lo que estamos frente a un modelo decente, pero definitivamente no el mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-meaning",
   "metadata": {},
   "source": [
    "## Modelo 2 - Preprocessing Significantes 90% varianza explicada\n",
    "\n",
    "Queremos ver ahora cómo actúa la regresión logística con las variables proyectadas por PCA con 90% de la varianza explicada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('tiene_alto_valor_adquisitivo')]\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "Y = df['tiene_alto_valor_adquisitivo']\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, Y, random_state=112)\n",
    "\n",
    "X_train_2, X_test_2 = preprocessing_significantes(X_train_2, X_test_2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "params = [{'penalty': ['l1']        , 'C': np.logspace(-3, 3, 7), 'solver': ['saga'] },\n",
    "          {'penalty': ['l2']        , 'C': np.logspace(-3, 3, 7), 'solver': ['lbfgs']},\n",
    "          {'penalty': ['elasticnet'], 'C': np.logspace(-3, 3, 7), 'solver': ['saga'] , 'l1_ratio': np.linspace(0.1, 0.9, 9)}]\n",
    "\n",
    "gscv2 = GridSearchCV(model, params, scoring='roc_auc', n_jobs=-1, verbose=4, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-myanmar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gscv2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-sacramento",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Los parámetros que mejor score obtuvieron para AdaBoost fueron:\", gscv2.best_params_)\n",
    "print(\"Con un Score (RocAUC) de: \", round(gscv2.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = gscv2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_2,lr2.predict(X_test_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-industry",
   "metadata": {},
   "source": [
    "Vemos que el modelo obtenido posee métricas similares al anterior modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(lr2, X_test_2, y_test_2, cmap=plt.cm.Blues, display_labels=['0', '1'], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-dictionary",
   "metadata": {},
   "source": [
    "La matriz de confusión tamibén es similar a la obtenida por el modelo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(lr2, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_2, lr2.predict_proba(X_test_2)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-wilson",
   "metadata": {},
   "source": [
    "La curva ROC y su puntuación AUC son decentes, pero podemos ver que no se trata del mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-panama",
   "metadata": {},
   "source": [
    "## Modelo 3 - mejores variables del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('tiene_alto_valor_adquisitivo')]\n",
    "X = pd.get_dummies(X)\n",
    "Y = df['tiene_alto_valor_adquisitivo']\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X, Y, random_state=27)\n",
    "\n",
    "X_train_3, X_test_3 = preprocessing.preprocessing_4_mejores_variables_arbol(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-collectible",
   "metadata": {},
   "source": [
    "### El árbol de decisión. Veamos qué variables elegimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import dtreeviz.trees as dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = DecisionTreeClassifier(min_samples_leaf=300, max_depth=5, random_state=27)\n",
    "arbol.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-major",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz = dtreeviz.dtreeviz(\n",
    "    arbol,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    target_name='tiene_alto_valor_adquisitivo',\n",
    "    feature_names=list(X.columns),\n",
    "    class_names=list([0,1]),\n",
    "    scale=1.5,\n",
    ")\n",
    "\n",
    "display(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-magnitude",
   "metadata": {},
   "source": [
    "##### Variables seleccionadas:\n",
    "(La selección la hacemos nosotors mirando las ganancias en separación con los pieplots)\n",
    "\n",
    "* Rol familiar registrado.\n",
    "* Años estudiados.\n",
    "* ganancia/perdida declarada en la bolsa.\n",
    "* Edad.\n",
    "* horas de trabajo registradas.\n",
    "\n",
    "Por lo que se usarán dichas variables para realizar la regresión, además se escalarán para poder aplicar regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horas_trabajo_registradas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_variables(X):\n",
    "    seleccion = ['rol_familiar_registrado_casado', 'anios_estudiados', 'ganancia_perdida_declarada_bolsa_argentina', 'edad', 'horas_trabajo_registradas']\n",
    "    return X[seleccion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('tiene_alto_valor_adquisitivo')]\n",
    "X = pd.get_dummies(X)\n",
    "X = filtrar_variables(X)\n",
    "Y = df['tiene_alto_valor_adquisitivo']\n",
    "\n",
    "# El mismo random_state nos asegura no estar provocando un leaking al seleccionar las variables.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-anatomy",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-classics",
   "metadata": {},
   "source": [
    "##### Primero se escalan las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train)).set_axis(X_train.columns, axis=1)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test)).set_axis(X_train.columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-alarm",
   "metadata": {},
   "source": [
    "##### Búsqueda de hiperparámetros con KFoldCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_jobs=-1, random_state=27)\n",
    "params = [{'penalty': ['l1']        , 'C': np.logspace(-3, 2, 6), 'solver': ['saga'] },\n",
    "          {'penalty': ['l2']        , 'C': np.logspace(-3, 2, 6), 'solver': ['lbfgs']},\n",
    "          {'penalty': ['elasticnet'], 'C': np.logspace(-3, 2, 6), 'solver': ['saga'] , 'l1_ratio': np.linspace(0.1, 0.9, 9)}]\n",
    "\n",
    "gscv = GridSearchCV(model, params, scoring='roc_auc', n_jobs=-1, cv=10, verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,gscv.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-governor",
   "metadata": {},
   "source": [
    "##### El modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = gscv.best_estimator_\n",
    "\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=100)\n",
    "plot_roc_curve(modelo, X_test, y_test, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4), dpi=150)\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(modelo, X_test, y_test, cmap=plt.cm.Blues, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
